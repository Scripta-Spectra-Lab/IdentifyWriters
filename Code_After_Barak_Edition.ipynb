{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "import re\n",
    "import statistics\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t, binom, norm, ks_2samp, ttest_ind, permutation_test\n",
    "import random\n",
    "from docx import Document as WordDocument\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Python_Scroll:\n",
    "    def __init__(self, file_path):\n",
    "        ext = file_path.lower().split('.')[-1]\n",
    "\n",
    "        if ext == 'txt':\n",
    "            self.data = self.extract_text_from_txt(file_path)\n",
    "        elif ext == 'docx':\n",
    "            docx_text = self.extract_text_from_docx(file_path)\n",
    "            self.data = pd.DataFrame({'Text': docx_text.split('\\n')})\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    def extract_text_from_txt(self, file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            result = chardet.detect(raw_data)\n",
    "            encoding = result['encoding']\n",
    "        return pd.read_csv(file_path, delimiter='\\t', encoding=encoding, header=None)\n",
    "\n",
    "    def extract_text_from_docx(self, docx_file):\n",
    "        doc = WordDocument(docx_file)\n",
    "        docx_text = []\n",
    "        for paragraph in doc.paragraphs:\n",
    "            docx_text.append(paragraph.text)\n",
    "        return '\\n'.join(docx_text)\n",
    "\n",
    "#####################\n",
    "### Preprocessing ###\n",
    "#####################\n",
    "\n",
    "# Data cleaning\n",
    "    def clean_data(self, save=0):\n",
    "        # Define a function to remove characters with big dots and the tab character\n",
    "        def remove_big_dots_and_tab(text):\n",
    "            cleaned_text = ''\n",
    "            for char in text:\n",
    "                if char == '֯' or char == '\\u200e':\n",
    "                    cleaned_text = cleaned_text[:-1]\n",
    "                    continue\n",
    "                else:\n",
    "                    cleaned_text += char\n",
    "            return cleaned_text\n",
    "\n",
    "        # Remove characters with big dots and the following tab character (like ת֯\\t)\n",
    "        self.data = self.data.applymap(remove_big_dots_and_tab)\n",
    "        \n",
    "        # Clean the data by removing content between '^' symbols\n",
    "        self.data = self.data.applymap(lambda x: x.replace('?', ''))  # Remove '?'\n",
    "        self.data = self.data.applymap(lambda x: x.replace('.', ''))  # Remove '.\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\{{.*?\\}}', '', str(x)))  # Remove {{***}}\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\⟦.*?\\⟧', '', str(x))) # remove ⟦***⟧\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\[.*?\\]', '', str(x))) # Remove [***]\n",
    "\n",
    "        # Remove characters with little dots above them (like נׄ), keeping the character itself\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\u05C4', '', str(x)))\n",
    "\n",
    "        #self.data = self.data.applymap(lambda x: x.replace('\\xa0', ''))  # Remove '\\xa0'\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\[.*?\\]', '', str(x)))\n",
    "        \n",
    "        self.original_data = self.data.copy() # create a copy for corrections computation\n",
    "        self.data = self.data.applymap(lambda x: re.sub(r'\\^.*?\\^', '', str(x))) # Remove ^***^\n",
    "\n",
    "        # Create new index columns based on the specified format\n",
    "        index_cols = self.data.iloc[:, -1].str.extract(r'(\\d+):(\\d+)', expand=True)\n",
    "        new_index_1 = index_cols[0]\n",
    "        new_index_2 = index_cols[1]\n",
    "\n",
    "        # Remove the \"*:*\" index from the lines\n",
    "        self.data.iloc[:, -1] = self.data.iloc[:, -1].str.replace(r'\\d+:\\d+', '', regex=True).str.strip()\n",
    "\n",
    "        # Reset the index to integer values\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "\n",
    "        # Set the new indexes to the existing data table\n",
    "        self.data.index = pd.MultiIndex.from_arrays([new_index_1, new_index_2])\n",
    "\n",
    "        # Reset the column names\n",
    "        self.data.columns = range(self.data.shape[1])\n",
    "\n",
    "        # Save the cleaned data to an Excel file using 'utf-8' encoding\n",
    "        if save == 1:    \n",
    "            self.save_to_word()\n",
    "            \n",
    "    def save_to_word(self):\n",
    "        document = WordDocument()\n",
    "\n",
    "        # Iterate through the data and add each cell as a paragraph\n",
    "        for i in range(self.data.shape[0]):\n",
    "            row = self.data.iloc[i].tolist()\n",
    "            for cell in row:\n",
    "                if pd.notna(cell):\n",
    "                    document.add_paragraph(str(cell))\n",
    "                else:\n",
    "                    document.add_paragraph(\"\")  # Add an empty paragraph for NaN values\n",
    "\n",
    "        # Save the document to a Word file\n",
    "        document.save(\"Cleaned_data.docx\")\n",
    "\n",
    "    def load_data(self, path):\n",
    "        self.t_data = pd.read_csv(path, delimiter='\\t', header=None, encoding='latin-1')\n",
    "        level_labels = ['Level1'] * len(self.data) + ['Level2'] * len(self.data)\n",
    "        self.t_data.index = pd.MultiIndex.from_tuples(zip(level_labels, self.data.index))\n",
    "        self.data = self.t_data\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.data)\n",
    "\n",
    "# Creating a new table of appearance of each word in plane and defective spelling\n",
    "\n",
    "    def word_counts(self, word_triplets_list):\n",
    "        # Initialize a new table to store the word counts\n",
    "        self.word_counts_table = pd.DataFrame()\n",
    "\n",
    "        for i, word_triplet in enumerate(word_triplets_list):\n",
    "            max_chars = 0\n",
    "            words = word_triplet[0]\n",
    "            max_chars = word_triplet[1] if len(word_triplet) > 1 else 0\n",
    "            allowed_chars = word_triplet[2] if len(word_triplet) > 2 else ()\n",
    "            word1, word2 = words\n",
    "\n",
    "            word1_column = f'{word1}'\n",
    "            word2_column = f'{word2}'\n",
    "\n",
    "            word1_counts = pd.DataFrame(columns=['col_1'], index=range(len(self.data.index.levels[0])))\n",
    "            word2_counts = pd.DataFrame(columns=['col_2'], index=range(len(self.data.index.levels[0])))\n",
    "\n",
    "            # Access data at the specified level using .xs\n",
    "            for high_index in self.data.index.levels[0]:\n",
    "                values = self.data.xs(high_index, level=0).squeeze().tolist()\n",
    "\n",
    "                defective_spelling_count = 0\n",
    "                plane_spelling_count = 0\n",
    "\n",
    "                for value in values:\n",
    "                    # Split value into words\n",
    "                    values_words = [word.strip() for word in value.split()]\n",
    "                    for i, value_word in enumerate(values_words):\n",
    "                        value_word = value_word.replace('\\u200F', '')\n",
    "                        len_value_word = len(value_word)\n",
    "                        if value_word.endswith(word1):\n",
    "                            if len_value_word == len(word1):\n",
    "                                defective_spelling_count += 1\n",
    "                            # the checking word is larger but in a possible length\n",
    "                            elif (len_value_word - len(word1) <= max_chars) and (len_value_word - len(word1) > 0):\n",
    "                                if allowed_chars != ():\n",
    "                                    if value_word.startswith(allowed_chars):\n",
    "                                        defective_spelling_count += 1\n",
    "                                else: # allowed_chars not specified, then all chars are premitted\n",
    "                                    defective_spelling_count += 1\n",
    "                                    \n",
    "                        elif value_word.endswith(word2):\n",
    "                            if len_value_word == len(word2):\n",
    "                                plane_spelling_count += 1\n",
    "                            # the checking word is larger but in a possible length\n",
    "                            elif (len_value_word - len(word2) <= max_chars) and (len_value_word - len(word2) > 0):\n",
    "                                if allowed_chars != ():\n",
    "                                    if value_word.startswith(allowed_chars):\n",
    "                                        plane_spelling_count += 1\n",
    "                                else: # allowed_chars not specified, then all chars are premitted\n",
    "                                    plane_spelling_count += 1\n",
    "                                    \n",
    "                word1_counts.iat[int(high_index) - 1, 0] = defective_spelling_count\n",
    "                word2_counts.iat[int(high_index) - 1, 0] = plane_spelling_count\n",
    "\n",
    "            self.word_counts_table[word1_column] = word1_counts\n",
    "            self.word_counts_table[word2_column] = word2_counts\n",
    "            \n",
    "# Concate new rows to table of words count (self.data)\n",
    "    def join_dataframes(self, file_path):\n",
    "        df = pd.read_excel(file_path)\n",
    "        self.word_counts_table = pd.concat([self.word_counts_table, df], axis=1)\n",
    "\n",
    "# Create a table for the statistical tests resalts\n",
    "    def create_tests_table(self, var_test=False, row_test=False, count_corrections=False):\n",
    "        # checking how many more columns to add (var and num of row tests)\n",
    "        boolean_vars = var_test + row_test + count_corrections\n",
    "        length = (len(self.word_counts_table.columns) // 2 + boolean_vars)\n",
    "        self.table = pd.DataFrame(columns=range(length))\n",
    "\n",
    "\n",
    "#####################\n",
    "# Statistical tests #\n",
    "#####################  \n",
    "    def TestDifference(self, start_1, stop_1, start_2, stop_2, test_name ='', p_thresh = 0.1, char_corrections='^'):\n",
    "        print(test_name)\n",
    "        #p_thresh = p_thresh/2\n",
    "        n_success_t = 0\n",
    "        n_success_p = 0\n",
    "        self.rellavent_data = self.word_counts_table\n",
    "        columns = self.rellavent_data.columns[:]\n",
    "        for i in range(0, len(self.word_counts_table.columns) , 2):\n",
    "            col_1, col_2 = columns[i], columns[i+1]\n",
    "            t_value = self.WaldTest(col_1, col_2, start_1, stop_1, start_2, stop_2)\n",
    "            if t_value:\n",
    "                p_value = self.PermuteWald(col_1, col_2, start_1, stop_1, start_2, stop_2, t_value, n_iter = 1000)\n",
    "                print(\"Column Names:\", col_1, col_2)\n",
    "                print(\"t_value: \", t_value)\n",
    "                print(\"p_value: \", p_value)\n",
    "                if t_value < p_thresh:\n",
    "                    n_success_t += 1\n",
    "                if p_value:\n",
    "                    if p_value < p_thresh:\n",
    "                        n_success_p += 1\n",
    "        \n",
    "        print(\"Row Variance Test:\")\n",
    "        self.compute_row_var()\n",
    "        t_value = self.student_t_test(self.var_table, start_1, stop_1, start_2, stop_2)\n",
    "        p_value = self.permutation_1_col(self.var_table, start_1, stop_1, start_2, stop_2)\n",
    "        print(\"t_value: \", t_value)\n",
    "        print(\"p_value: \", p_value)\n",
    "        if t_value:\n",
    "            if t_value < p_thresh:\n",
    "                n_success_t += 1\n",
    "        if p_value:\n",
    "            if p_value < p_thresh:\n",
    "                n_success_p += 1\n",
    "\n",
    "        print(\"Number of Rows Test:\")\n",
    "        self.compute_column_num_of_rows()\n",
    "        t_value = self.student_t_test(self.num_of_rows_column, start_1, stop_1, start_2, stop_2)\n",
    "        p_value = self.permutation_1_col(self.num_of_rows_column, start_1, stop_1, start_2, stop_2)\n",
    "        print(\"t_value: \", t_value)\n",
    "        print(\"p_value: \", p_value)\n",
    "        if t_value:\n",
    "            if t_value < p_thresh:\n",
    "                n_success_t += 1\n",
    "        if p_value:\n",
    "            if p_value < p_thresh:\n",
    "                n_success_p += 1\n",
    "\n",
    "        print(\"Number of Corrections Test:\")\n",
    "        self.count_corrections(char_corrections)\n",
    "        t_value = self.student_t_test(self.corrections, start_1, stop_1, start_2, stop_2)\n",
    "        p_value = self.permutation_1_col(self.corrections, start_1, stop_1, start_2, stop_2)\n",
    "        if t_value:\n",
    "            if t_value < p_thresh:\n",
    "                n_success_t += 1\n",
    "        if p_value:\n",
    "            if p_value < p_thresh:\n",
    "                n_success_p += 1\n",
    "        \n",
    "        return n_success_t, n_success_p\n",
    "    \n",
    "    def PermuteTestDifference(self, null_range, start, stop, n_iter = 100, test_name ='', p_thresh = 0.1, char_corrections='^'):\n",
    "        n_sucesses = np.zeros((2, n_iter))\n",
    "        for j in range(n_iter):\n",
    "            if j%100 == 0:\n",
    "                print(f\"Wald permutation test num: {j}\")\n",
    "                continue\n",
    "            permuted_indices = np.random.permutation(null_range)\n",
    "            self.rellavent_data = self.word_counts_table.iloc[permuted_indices]\n",
    "        return\n",
    "    \n",
    "        \n",
    "    def WaldTest_WithData(self, col_1_data_1, col_2_data_1, col_1_data_2, col_2_data_2):\n",
    "        \n",
    "        n_obs_1 = col_1_data_1.sum() + col_2_data_1.sum()\n",
    "        n_obs_2 = col_1_data_2.sum() + col_2_data_2.sum()\n",
    "        \n",
    "        if n_obs_1 == 0 or n_obs_2 == 0:\n",
    "            return ''            \n",
    "        \n",
    "        p_1 = col_1_data_1.sum()/n_obs_1\n",
    "        p_2 = col_1_data_2.sum()/n_obs_2\n",
    "        p_h = (n_obs_1*p_1 + n_obs_2*p_2) / (n_obs_1+n_obs_2)\n",
    "\n",
    "        sd_h = math.sqrt(p_h*(1-p_h)*(1/n_obs_1 + 1/n_obs_2))\n",
    "        if sd_h == 0:\n",
    "            return ''\n",
    "        \n",
    "        degrees_of_freedom = n_obs_1 + n_obs_2 -2\n",
    "        if degrees_of_freedom + 2 >= 30:\n",
    "            return self.update_p_value(norm.cdf((p_2 - p_1) / sd_h))\n",
    "        else:\n",
    "            return self.update_p_value(t.cdf((p_2 - p_1) / sd_h, degrees_of_freedom))\n",
    "        \n",
    "    def WaldTest(self, col_1, col_2, start_1, stop_1, start_2, stop_2):\n",
    "        col_1_data_1 = self.read_col(col_1, start_1, stop_1)\n",
    "        col_2_data_1 = self.read_col(col_2, start_1, stop_1)\n",
    "        col_1_data_2 = self.read_col(col_1, start_2, stop_2)\n",
    "        col_2_data_2 = self.read_col(col_2, start_2, stop_2)\n",
    "        return self.WaldTest_WithData(col_1_data_1, col_2_data_1, col_1_data_2, col_2_data_2)\n",
    "\n",
    "\n",
    "    def PermuteWald(self, col_1, col_2, start_1, stop_1, start_2, stop_2, t_value, n_iter = 1000):\n",
    "        tests_results = []\n",
    "        indexes_to_shuffle = np.concatenate((np.arange(start_1-1, stop_1), np.arange(start_2-1, stop_2)) )\n",
    "        n_obs_1 = stop_1 - start_1\n",
    "        #n_obs_2 = stop_2 - start_2\n",
    "        for j in range(n_iter):\n",
    "            if j%100 == 0:\n",
    "                #print(f\"Wald permutation test num: {j}\")\n",
    "                continue\n",
    "            permuted_indices = np.random.permutation(indexes_to_shuffle)\n",
    "            col_1_data = self.read_col_at_indices(col_1, permuted_indices)\n",
    "            col_2_data = self.read_col_at_indices(col_2, permuted_indices)\n",
    "            col_1_data_1 = col_1_data[:n_obs_1+1]\n",
    "            col_2_data_1 = col_2_data[:n_obs_1+1]\n",
    "            col_1_data_2 = col_1_data[n_obs_1+1:]\n",
    "            col_2_data_2 = col_2_data[n_obs_1+1:]\n",
    "            statistic_value = self.WaldTest_WithData(col_1_data_1, col_2_data_1, col_1_data_2, col_2_data_2)\n",
    "            if statistic_value:\n",
    "                tests_results.append(statistic_value)\n",
    "\n",
    "        self.rellavent_data = self.word_counts_table\n",
    "        if len(tests_results)==0:\n",
    "            return ''     \n",
    "        return sum(1 for num in tests_results if num <= t_value) / len(tests_results)\n",
    "\n",
    "    def PermuteWald_WithData(self, col_1_data, col_2_data, start_1, stop_1, start_2, stop_2, t_value, n_iter = 1000):\n",
    "        tests_results = []\n",
    "        indexes_to_shuffle = np.concatenate((np.arange(start_1-1, stop_1), np.arange(start_2-1, stop_2)) )\n",
    "        n_obs_1 = stop_1 - start_1\n",
    "        #n_obs_2 = stop_2 - start_2\n",
    "        for j in range(n_iter):\n",
    "            if j%100 == 0:\n",
    "                #print(f\"Wald permutation test num: {j}\")\n",
    "                continue\n",
    "            permuted_indices = np.random.permutation(indexes_to_shuffle)\n",
    "            col_1_data_shuffled = col_1_data[permuted_indices]\n",
    "            col_2_data_shuffled = col_2_data[permuted_indices]\n",
    "            col_1_data_1 = col_1_data_shuffled[:n_obs_1+1]\n",
    "            col_2_data_1 = col_2_data_shuffled[:n_obs_1+1]\n",
    "            col_1_data_2 = col_1_data_shuffled[n_obs_1+1:]\n",
    "            col_2_data_2 = col_2_data_shuffled[n_obs_1+1:]\n",
    "            statistic_value = self.WaldTest_WithData(col_1_data_1, col_2_data_1, col_1_data_2, col_2_data_2)\n",
    "            if statistic_value:\n",
    "                tests_results.append(statistic_value)\n",
    "\n",
    "        self.rellavent_data = self.word_counts_table\n",
    "        if len(tests_results)==0:\n",
    "            return ''     \n",
    "        return sum(1 for num in tests_results if num <= t_value) / len(tests_results)    \n",
    "        \n",
    "# Calculation of the statistics for the test\n",
    "    def orgenizing_statistical_tests(self, start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, test_name ='', var_test=False, row_test=False, count_corrections=False, char_corrections=''):\n",
    "        self.rellavent_data = self.word_counts_table\n",
    "        self.statistical_tests(start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, test_name, var_test, row_test, count_corrections, char_corrections)\n",
    "        self.export_table_statistical_test()\n",
    "        \n",
    "    def statistical_tests(self, start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, test_name, var_test, row_test, count_corrections, char_corrections):\n",
    "        columns = self.rellavent_data.columns[:]  # Exclude the first column\n",
    "        data = [np.nan] * len(self.table.columns)\n",
    "        new_row = pd.Series(data, index=self.table.columns, name=test_name)\n",
    "        #self.table = self.table.append(new_row)\n",
    "        self.table = pd.concat([self.table, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        for i in range(0, len(self.word_counts_table.columns) , 2):\n",
    "            col_1, col_2 = columns[i], columns[i+1]\n",
    "            if type_of_test == 't_test':\n",
    "                p_value = self.t_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            elif type_of_test == 'permutation':\n",
    "                t_value = self.t_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                p_value = self.hand_permutation_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0, t_value)\n",
    "            else: \n",
    "                raise('An incorrect test type was entered in the function')\n",
    "\n",
    "            p_value = self.update_p_value(p_value)\n",
    "            #print(p_value)\n",
    "            self.table.iloc[-1, i//2] = p_value\n",
    "            self.table.rename(columns={self.table.columns[i//2]: col_1}, inplace=True)\n",
    "    \n",
    "# Additional tests if chekcing row's var or/and num of rows tests\n",
    "        if var_test == True:\n",
    "            self.compute_row_var()\n",
    "            if type_of_test == 't_test': \n",
    "                p_value = self.student_t_test(self.var_table, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            elif type_of_test == 'permutation':\n",
    "                p_value = self.permutation_1_col(self.var_table, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            p_value = self.update_p_value(p_value)\n",
    "            self.table.iloc[-1, i//2 + var_test] = p_value\n",
    "            self.table.rename(columns={self.table.columns[i//2 +var_test]: 'row_variance'}, inplace=True)\n",
    "\n",
    "        if row_test == True:\n",
    "            self.compute_column_num_of_rows()\n",
    "            if type_of_test == 't_test': \n",
    "                p_value = self.student_t_test(self.num_of_rows_column, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            elif type_of_test == 'permutation':\n",
    "                p_value = self.permutation_1_col(self.num_of_rows_column, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            p_value = self.update_p_value(p_value)\n",
    "            self.table.iloc[-1, i//2 + var_test + row_test] = p_value\n",
    "            self.table.rename(columns={self.table.columns[i//2 + var_test + row_test]: 'num_of_rows'}, inplace=True)\n",
    "\n",
    "        if count_corrections == True:\n",
    "            self.count_corrections(char_corrections)\n",
    "            if type_of_test == 't_test': \n",
    "                p_value = self.student_t_test(self.corrections, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            elif type_of_test == 'permutation':\n",
    "                p_value = self.permutation_1_col(self.corrections, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            p_value = self.update_p_value(p_value)\n",
    "            self.table.iloc[-1, i//2 + var_test + row_test + count_corrections] = p_value\n",
    "            self.table.rename(columns={self.table.columns[i//2 + var_test + row_test + count_corrections]: 'overall corrections'}, inplace=True)\n",
    "\n",
    "    def read_col(self, col, start, stop):\n",
    "        return self.rellavent_data[col].iloc[start:stop+1]\n",
    "    def read_col_at_indices(self, col, indices):\n",
    "        return self.rellavent_data[col].iloc[indices]\n",
    "# Computing the odds to recieve the empirical results assuming \n",
    "    # T distribution\n",
    "    def t_test(self, col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0):\n",
    "        col_1_data_h0 = self.read_col(col_1, start_writer_h0, end_writer_h0)\n",
    "        col_2_data_h0 = self.read_col(col_2, start_writer_h0, end_writer_h0)\n",
    "        col_1_data = self.read_col(col_1, start_row, stop_row)\n",
    "        col_2_data = self.read_col(col_2, start_row, stop_row)\n",
    "        \n",
    "        n_obs_h0 = col_1_data_h0.sum() + col_2_data_h0.sum()\n",
    "        n_obs = col_1_data.sum() + col_2_data.sum()\n",
    "        \n",
    "        # p_h = self.calculate_mean(col_1, col_2, start_row, stop_row)\n",
    "        # p_h0 = self.calculate_mean(col_1, col_2, start_writer_h0, end_writer_h0)\n",
    "        # #var_0 = self.empirical_var(col_1, col_2, start_writer_h0, end_writer_h0)\n",
    "        # if start_writer_h0 == start_row:\n",
    "        #     p_h1 = self.calculate_mean(col_1, col_2, end_writer_h0+1, stop_row)\n",
    "        #     #var_1 = self.empirical_var(col_1, col_2, end_writer_h0+1, stop_row)\n",
    "        # else:\n",
    "        #     p_h1 = self.calculate_mean(col_1, col_2, start_row, start_writer_h0-1)\n",
    "        #     #var_1 = self.empirical_var(col_1, col_2, start_row, start_writer_h0-1)\n",
    "        # # if var not defined then return '' \n",
    "        \n",
    "        # num_obs_h0 = self.calculate_sum(col_1, col_2, start_writer_h0, end_writer_h0)\n",
    "        # num_obs_h1 = self.calculate_sum(col_1, col_2, start_row, stop_row) - num_obs_h0\n",
    "        if n_obs_h0 == 0 or n_obs == 0:\n",
    "            return ''            \n",
    "        \n",
    "        p_h0 = col_1_data_h0.sum()/n_obs_h0\n",
    "        p = col_1_data.sum()/n_obs\n",
    "        \n",
    "        sd_h = math.sqrt(p*(1-p)*(1/n_obs_h0 + 1/n_obs))\n",
    "        if sd_h == 0:\n",
    "            return ''\n",
    "        \n",
    "        # joined_sd = math.sqrt(((num_obs_h0 - 1)*var_0 + (num_obs_h1 - 1)*var_1) / \n",
    "        #             (num_obs_h0 + num_obs_h1 - 2))\n",
    "        # joined_sd_for_means = joined_sd * math.sqrt(1/num_obs_h0 + 1/num_obs_h1)\n",
    "        \n",
    "        # degrees_of_freedom = self.calculate_sum(col_1, col_2, start_row, stop_row)-2\n",
    "        return norm.cdf((p - p_h0) / sd_h)\n",
    "\n",
    "    \n",
    "    # compute permutation distribution\n",
    "    def hand_permutation_test(self, col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0, t_value):\n",
    "        tests_results = []\n",
    "        for j in range(NUM_PERMUTATIONS):\n",
    "            #print(f\"Hypothesis permutatuin test num: {j}\")\n",
    "            self.rellavent_data = self.word_counts_table.copy()            \n",
    "            self.rellavent_data = self.rellavent_data.loc[:, [col_1, col_2]]\n",
    "            \n",
    "            indexes_to_shuffle = np.arange(start_row-1, stop_row)\n",
    "            np.random.shuffle(indexes_to_shuffle)\n",
    "            self.rellavent_data.iloc[start_row-1:stop_row, :] = self.word_counts_table.loc[indexes_to_shuffle, [col_1, col_2]]\n",
    "            p_value = self.t_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "            if p_value:\n",
    "                tests_results.append(p_value)\n",
    "\n",
    "        self.rellavent_data = self.word_counts_table\n",
    "        if len(tests_results)==0:\n",
    "            return ''     \n",
    "        return sum(1 for num in tests_results if num <= t_value) / len(tests_results)\n",
    "    \n",
    "# calculate p = the empirical parameter of bernoli distribution\n",
    "    def calculate_mean(self, col_1, col_2, start_writer_h0, end_writer_h0):\n",
    "        col_1_data = self.rellavent_data[col_1].iloc[start_writer_h0-1:end_writer_h0].tolist()\n",
    "        col_2_data = self.rellavent_data[col_2].iloc[start_writer_h0-1:end_writer_h0].tolist()\n",
    "        if self.calculate_sum(col_1, col_2, start_writer_h0, end_writer_h0) != 0:\n",
    "            return sum(col_1_data) / self.calculate_sum(col_1, col_2, start_writer_h0, end_writer_h0)\n",
    "        else:\n",
    "            return 'division by zero'\n",
    "\n",
    "# calculate N = the number of appernace of the rellavent word in both first and seconed writers\n",
    "    def calculate_sum(self, col_1, col_2, start_writer_h0, end_writer_h0):\n",
    "        col_1_data = self.rellavent_data[col_1].iloc[start_writer_h0-1:end_writer_h0].tolist()\n",
    "        col_2_data = self.rellavent_data[col_2].iloc[start_writer_h0-1:end_writer_h0].tolist()\n",
    "        return sum(col_1_data) + sum(col_2_data)\n",
    "\n",
    "# calculate N_1 = the number of appernace of the rellavent word in 1 format only\n",
    "    def calculate_success(self, col_1, start_writer_h0, end_writer_h0):\n",
    "        col_1_data = self.rellavent_data[col_1].iloc[start_writer_h0-1:end_writer_h0].tolist()\n",
    "        return sum(col_1_data)\n",
    "\n",
    "# Calculate s.d. for givven columns\n",
    "    def empirical_var(self, col_1, col_2, start_writer_h0, end_writer_h0):\n",
    "        if self.calculate_sum(col_1, col_2, start_writer_h0, end_writer_h0)-1 == 0 or self.calculate_mean(col_1, col_2, start_writer_h0, end_writer_h0)=='division by zero':\n",
    "            return ''\n",
    "        meanning_the_sum_of_squers = 1 / (self.calculate_sum(col_1, col_2, start_writer_h0, end_writer_h0)-1)\n",
    "        sum_of_squers_for_success_columns = sum([i*(1 - self.calculate_mean(col_1, col_2, start_writer_h0, end_writer_h0)) ** 2 for i in self.rellavent_data[col_1].iloc[start_writer_h0 - 1 : end_writer_h0].tolist()])                     \n",
    "        sum_of_squers_for_unsuccess_columns = sum([i*(0 - self.calculate_mean(col_1, col_2, start_writer_h0, end_writer_h0)) ** 2 for i in self.rellavent_data[col_2].iloc[start_writer_h0 - 1 : end_writer_h0].tolist()])                     \n",
    "        var = meanning_the_sum_of_squers*(sum_of_squers_for_success_columns+sum_of_squers_for_unsuccess_columns)\n",
    "        return var\n",
    "########################\n",
    "# QUESTION : WHY DO YOU DO THAT?\n",
    "# update p_value\n",
    "    def update_p_value(self, p_value):\n",
    "        if p_value == '':\n",
    "            return ''\n",
    "        elif p_value> 0.5:\n",
    "            return 1-p_value\n",
    "        return p_value\n",
    "    \n",
    "    def export_table_statistical_test(self):\n",
    "        self.table.to_csv(\"Updated_Significance_Tests_Table_11.csv\")\n",
    "\n",
    "# Filling up the tables\n",
    "    def create_table_permutation_tests(self, length=20):\n",
    "        row_names = range(length + 1)\n",
    "        self.permutation_table = pd.DataFrame(index=range(length + 1))\n",
    "            \n",
    "    def update_table_with_counts_proportion(self, test_name):\n",
    "        # add an empty row to self.table\n",
    "        data = [np.nan] * len(self.permutation_table.index)\n",
    "        new_column = pd.Series(data, index=self.permutation_table.index, name=test_name)\n",
    "        self.permutation_table = pd.concat([self.permutation_table, new_column], axis=1)\n",
    "        \n",
    "        # Count the occurrences of each number in self.tests_results\n",
    "        counts = {i: self.tests_results.count(i) for i in range(len(self.permutation_table.index))}\n",
    "\n",
    "        list_length = len(self.tests_results)\n",
    "\n",
    "        # Update the values in the specified row of the table\n",
    "        for row_idx, count in counts.items():\n",
    "            self.permutation_table.at[row_idx, test_name] = count / list_length\n",
    "\n",
    "    def export_table_permutaion_tests(self):\n",
    "        self.table.to_csv(\"Updated_Significance_Tests_Table_11.csv\")\n",
    "\n",
    "######################\n",
    "## row's length var ##\n",
    "######################\n",
    "\n",
    "# Functions for computing num of words and letters in a row\n",
    "    def replace_with_letter_count(self):\n",
    "        # Create a new DataFrame with the same shape as the original table\n",
    "        new_data = pd.DataFrame(index=self.data.index, columns=self.data.columns)\n",
    "\n",
    "        # Function to count letters in a string (excluding spaces)\n",
    "        def count_letters(text):\n",
    "            return len(re.sub(r'\\s', '', str(text)))\n",
    "\n",
    "        # Iterate over each cell in the original table\n",
    "        for row_idx, row in self.data.iterrows():\n",
    "            for col_idx, cell in row.items():\n",
    "                # Count the letters in the cell (excluding spaces)\n",
    "                letter_count = count_letters(cell)\n",
    "                # Assign the letter count to the corresponding cell in the new table\n",
    "                new_data.loc[row_idx, col_idx] = letter_count\n",
    "\n",
    "        self.letters_rows_count = new_data\n",
    "\n",
    "    def compute_row_var(self):\n",
    "        # Calculate the mean and standard deviation for each group\n",
    "        self.replace_with_letter_count()\n",
    "        group_stats = self.letters_rows_count.groupby(level=0).agg(['var'])\n",
    "        group_stats.index = group_stats.index.astype(int)\n",
    "        \n",
    "        # Sort the DataFrame based on the first index values\n",
    "        self.var_table = group_stats.sort_index()\n",
    "\n",
    "#####################\n",
    "## rows in columns ##\n",
    "#####################\n",
    "    def compute_column_num_of_rows(self):\n",
    "        # Calculate the mean and standard deviation for each group\n",
    "        self.replace_with_letter_count()\n",
    "        group_stats = self.letters_rows_count.groupby(level=0).agg(['count'])\n",
    "        group_stats.index = group_stats.index.astype(int)\n",
    "        \n",
    "        # Sort the DataFrame based on the first index values\n",
    "        self.num_of_rows_column = group_stats.sort_index()\n",
    "        self.num_of_rows_column.at[self.num_of_rows_column.index[-1],0] = self.num_of_rows_column[self.num_of_rows_column.columns[0]].mean()\n",
    "\n",
    "#####################\n",
    "# count corrections #\n",
    "#####################\n",
    "    def count_corrections(self, char_corrections):\n",
    "        \n",
    "        # Apply the clean_text function to each element in the DataFrame\n",
    "        self.data_t = self.data.copy()\n",
    "        self.data = self.original_data.copy()\n",
    "        \n",
    "        # Create new index columns based on the specified format\n",
    "        index_cols = self.data.iloc[:, -1].str.extract(r'(\\d+):(\\d+)', expand=True)\n",
    "        new_index_1 = index_cols[0]\n",
    "        new_index_2 = index_cols[1]\n",
    "\n",
    "        # Remove the \"*:*\" index from the lines\n",
    "        self.data.iloc[:, -1] = self.data.iloc[:, -1].str.replace(r'\\d+:\\d+', '', regex=True).str.strip()\n",
    "\n",
    "        # Reset the index to integer values\n",
    "        self.data = self.data.reset_index(drop=True)\n",
    "\n",
    "        # Set the new indexes to the existing data table\n",
    "        self.data.index = pd.MultiIndex.from_arrays([new_index_1, new_index_2])\n",
    "\n",
    "        # Reset the column names\n",
    "        self.data.columns = range(self.data.shape[1])\n",
    "        \n",
    "        self.corrections = self.count_num_of_corrections(char_corrections)\n",
    "        self.data = self.data_t.copy()\n",
    "        \n",
    "    def count_num_of_corrections(self, char_corrections):                                     \n",
    "        data = pd.DataFrame(columns=self.data.columns, index=range(1,len(self.data.index.levels[0])+1))\n",
    "\n",
    "        for high_index in self.data.index.levels[0]:\n",
    "            values = self.data.xs(high_index, level=0).squeeze().tolist()\n",
    "            corrections = (sum(item.count(char_corrections) for item in values))/2\n",
    "            data.iat[int(high_index) - 1, 0] = corrections\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#### test 2 dist ####\n",
    "#####################\n",
    "    def student_t_test(self, data_to_test, start_row, stop_row, start_writer_h0, end_writer_h0):\n",
    "        \n",
    "        group_0 = data_to_test.iloc[start_writer_h0-1:end_writer_h0, 0].tolist()\n",
    "        group_1 = data_to_test.iloc[start_row-1:stop_row, 0].tolist()\n",
    "        # if start_writer_h0 == start_row:\n",
    "        #     group_1 = data_to_test.iloc[end_writer_h0:stop_row, 0].tolist()\n",
    "        # else:\n",
    "        #     group_1 = data_to_test.iloc[start_row-1:start_writer_h0-1, 0].tolist()\n",
    "        student_t_test_result = ttest_ind(a=group_0, b=group_1, equal_var=True, alternative='less')\n",
    "        return student_t_test_result.pvalue\n",
    "    \n",
    "    def permutation_1_col(self, data_to_test, start_row, stop_row, start_writer_h0, end_writer_h0):\n",
    "        group_0 = data_to_test.iloc[start_writer_h0-1:end_writer_h0, 0].tolist()\n",
    "        group_1 = data_to_test.iloc[start_row-1:stop_row, 0].tolist()\n",
    "        \n",
    "        #group_1 = (data_to_test.iloc[end_writer_h0:stop_row, 0] if start_writer_h0 == start_row else data_to_test.iloc[start_row-1:start_writer_h0-1, 0]).tolist()\n",
    "\n",
    "        # Remove empty values from the lists\n",
    "        group_0 = [val for val in group_0 if not np.isnan(val)]\n",
    "        group_1 = [val for val in group_1 if not np.isnan(val)]\n",
    "\n",
    "        # Check if both lists are empty and return np.nan\n",
    "        if not group_0 or not group_1:\n",
    "            return np.nan\n",
    "\n",
    "        if np.sum(group_0 == np.nan) > 0 or np.sum(group_1 == np.nan) > 0:\n",
    "            print(\"Something Fishy\")\n",
    "        p_value = permutation_test(data=(group_0, group_1), statistic=self.t_test_for_permutation, permutation_type='independent',\n",
    "                                   vectorized=True, n_resamples=1000, alternative='less', axis=0)\n",
    "\n",
    "        # Convert back to np.nan if p_value is zero-dimensional\n",
    "        if np.isscalar(p_value):\n",
    "            p_value = np.nan\n",
    "\n",
    "        return p_value.pvalue\n",
    "\n",
    "    def t_test_for_permutation(self, x_list, y_list, axis):\n",
    "        x_array = np.array(x_list)\n",
    "        y_array = np.array(y_list)\n",
    "\n",
    "        if len(x_array) < 1 or len(y_array) < 1:\n",
    "            return np.nan  # Return np.nan instead of ''\n",
    "\n",
    "        _, p_value = ttest_ind(x_array, y_array, axis=axis)\n",
    "        return p_value\n",
    "        \n",
    "#####################\n",
    "# permutation tests #\n",
    "#####################  \n",
    "\n",
    "#  function\n",
    "    def permutation_tests(self, start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, bootstrap=0, test_name='', column_index_to_start=0, num_iterations=10000, var_test=False, row_test=False, count_corrections=False):\n",
    "        self.counting_successful_tests(start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, bootstrap, column_index_to_start, num_iterations, var_test, row_test, count_corrections)\n",
    "        self.update_table_with_counts_proportion(test_name)\n",
    "        self.export_table_permutaion_tests()\n",
    "\n",
    "# define the rows to be tested and the transaction in wrtiers\n",
    "    def counting_successful_tests(self, start_row, stop_row, start_writer_h0, end_writer_h0, type_of_test, bootstrap, column_index_to_start, num_iterations, var_test, row_test, count_corrections):\n",
    "        # shaffling the data 'num_iterations' times\n",
    "        tests_results = []\n",
    "        for j in range (num_iterations):\n",
    "            print(j)\n",
    "            counter = 0 \n",
    "            indexes_to_shuffle = self.bootstrap_data(start_row, stop_row, start_writer_h0, end_writer_h0) if bootstrap == 1 else self.preprocess_data(start_row, stop_row)\n",
    "            print(indexes_to_shuffle)\n",
    "            # compute tests for each columns pair\n",
    "            for i in range(column_index_to_start,len(self.rellavent_data.columns)-2,2):\n",
    "                columns = self.rellavent_data.columns[column_index_to_start:]\n",
    "                col_1, col_2 = columns[i], columns[i+1]\n",
    "                if type_of_test == 't_test':\n",
    "                    p_value = self.t_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                elif type_of_test == 'permutation':\n",
    "                    t_value = self.t_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                    p_value = self.hand_permutation_test(col_1, col_2, start_row, stop_row, start_writer_h0, end_writer_h0, t_value)\n",
    "                else: \n",
    "                    raise('An incorrect test type was entered in the function')\n",
    "                p_value = self.update_p_value(p_value)\n",
    "                if p_value == '':\n",
    "                    continue \n",
    "                else:\n",
    "                    if p_value <= 0.05:\n",
    "                        counter += 1\n",
    "\n",
    "            # to var of rows and num of rows            \n",
    "            if var_test == True:\n",
    "                self.copy_var_table = self.var_table.copy()\n",
    "                self.copy_var_table.iloc[np.arange(start_row-1, stop_row), :] = self.var_table.iloc[indexes_to_shuffle, :]\n",
    "                if type_of_test == 't_test': \n",
    "                    p_value = self.student_t_test(self.copy_var_table, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                elif type_of_test == 'permutation':\n",
    "                    p_value = self.permutation_1_col(self.copy_var_table, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                p_value = self.update_p_value(p_value)\n",
    "                if p_value <= 0.05:\n",
    "                    counter += 1             \n",
    "                \n",
    "            if row_test == True:\n",
    "                self.copy_num_of_rows_column = self.num_of_rows_column.copy()\n",
    "                self.copy_num_of_rows_column.iloc[np.arange(start_row-1, stop_row), :] = self.num_of_rows_column.iloc[indexes_to_shuffle, :]\n",
    "                if type_of_test == 't_test': \n",
    "                    p_value = self.student_t_test(self.copy_num_of_rows_column, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                elif type_of_test == 'permutation':\n",
    "                    p_value = self.permutation_1_col(self.copy_num_of_rows_column, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                p_value = self.update_p_value(p_value)\n",
    "                if p_value <= 0.05:\n",
    "                    counter += 1\n",
    "                    \n",
    "            if count_corrections == True:\n",
    "                self.copy_corrections = self.corrections.copy()\n",
    "                self.copy_corrections.iloc[np.arange(start_row-1, stop_row), :] = self.corrections.iloc[indexes_to_shuffle, :]\n",
    "                if type_of_test == 't_test': \n",
    "                    p_value = self.student_t_test(self.copy_corrections, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                elif type_of_test == 'permutation':\n",
    "                    p_value = self.permutation_1_col(self.copy_corrections, start_row, stop_row, start_writer_h0, end_writer_h0)\n",
    "                p_value = self.update_p_value(p_value)\n",
    "                if p_value <= 0.05:\n",
    "                    counter += 1\n",
    "                                    \n",
    "            tests_results.append(counter)\n",
    "        self.tests_results = tests_results\n",
    "                  \n",
    "            \n",
    "                       \n",
    "    def preprocess_data(self, start_row, stop_row):\n",
    "        # choozing rows for rellavant tests\n",
    "        self.rellavent_data = self.word_counts_table.copy()\n",
    "        indexes_to_shuffle = np.arange(start_row-1, stop_row)\n",
    "        np.random.shuffle(indexes_to_shuffle)\n",
    "        self.rellavent_data.iloc[np.arange(start_row-1, stop_row), :] = self.word_counts_table.iloc[indexes_to_shuffle, :]\n",
    "        \n",
    "        # Computing row var and row num\n",
    "        self.compute_row_var()\n",
    "        self.compute_column_num_of_rows()\n",
    "        \n",
    "        return indexes_to_shuffle\n",
    "\n",
    "    def bootstrap_data(self, start_row, stop_row, start_writer_h0, end_writer_h0, random_seed=None):\n",
    "        num_samples = stop_row - start_row + 1\n",
    "        if random_seed is not None:\n",
    "            random.seed(random_seed)  # Set the random seed if provided\n",
    "\n",
    "        # Sample row indexes within the specified range with replacement\n",
    "        sampled_indexes = random.choices(range(start_writer_h0, end_writer_h0), k=num_samples)\n",
    "\n",
    "        # Create a new DataFrame from the sampled rows\n",
    "        self.rellavent_data = self.word_counts_table.iloc[sampled_indexes]\n",
    "\n",
    "        # Return the sampled row indexes (with duplicates)\n",
    "        return sampled_indexes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "NUM_PERMUTATIONS = np.int16(1e3)\n",
    "STAGE = 0#7\n",
    "file_path = r\"C:\\Users\\yisha\\OneDrive\\Documents\\Thesis\\DSS\\1QIsaa 1-without_verses.docx\"\n",
    "concated_data_path = r\"C:\\Users\\yisha\\OneDrive\\Documents\\Thesis\\DSS\\DSS_Data_verbs_data.xlsx\"\n",
    "output_file = r\"./Letters_count.xlsx\"\n",
    "if STAGE==0:\n",
    "    data = Python_Scroll(file_path)\n",
    "    data.clean_data() # can also save the new data\n",
    "    #data.load_data('C:\\\\Users\\\\yisha\\\\PycharmProjects\\\\pythonProject\\\\Thesis\\\\Cleaned_data.txt')\n",
    "    data.word_counts([(('כי','כיא'),1,('ו','ה')),(('לי','ליא'),1,('ו')), (('מי','מיא'),1,('מ','ב','ל','כ','ו')), (('כה','כוה'),1,('ו', 'ה')), (('הוא','הואה'),1,('ו', 'ה')), (('כל','כול'),2 ,('מ','ב','ל','כ','ו', 'ה')), (('ירושלם','ירושלים'),2)])\n",
    "    data.join_dataframes(concated_data_path)\n",
    "    data.create_tests_table(var_test=True, row_test=True, count_corrections=True)\n",
    "    data.compute_row_var()\n",
    "    data.compute_column_num_of_rows()\n",
    "    n_success_t, n_success_p = data.TestDifference(start_1 = 1, stop_1 = 11, start_2 = 12, stop_2 = 27, test_name = \"\\n######\\n1 vs 2\\n######\\n\")\n",
    "    print(\"Number of successes:\\n t = \", n_success_t, \"| p = \", n_success_p)\n",
    "    n_success_t, n_success_p = data.TestDifference(start_1 = 28, stop_1 = 54, start_2 = 1, stop_2 = 11, test_name = \"\\n######\\n1 vs 3\\n######\\n\")\n",
    "    print(\"Number of successes:\\n t = \", n_success_t, \"| p = \", n_success_p)\n",
    "    n_success_t, n_success_p = data.TestDifference(start_1 = 28, stop_1 = 54, start_2 = 12, stop_2 = 27, test_name = \"\\n######\\n2 vs 3\\n######\\n\")\n",
    "    print(\"Number of successes:\\n t = \", n_success_t, \"| p = \", n_success_p)\n",
    "    data.orgenizing_statistical_tests(start_row=28, stop_row=54, start_writer_h0=12, end_writer_h0=27,\n",
    "                                        type_of_test='t_test', test_name ='t_test_3_2',var_test=True, row_test=True, count_corrections=True, char_corrections='^')\n",
    "    file = open('./Stage1', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "else:\n",
    "    file = open('./Stage'+str(STAGE), 'rb')\n",
    "    pick_data = pickle.load(file)\n",
    "    data = pick_data\n",
    "    file.close()\n",
    "\n",
    "if STAGE < 2:\n",
    "    data.orgenizing_statistical_tests(start_row=1, stop_row=27, start_writer_h0=12, end_writer_h0=27,\n",
    "                                        type_of_test='t_test', test_name ='t_test_1_2',var_test=True, row_test=True, count_corrections=True, char_corrections='^')\n",
    "    file = open('./Stage2', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 3:\n",
    "    data.orgenizing_statistical_tests(start_row=12, stop_row=54, start_writer_h0=12, end_writer_h0=27,\n",
    "                                        type_of_test='permutation', test_name ='permutation_3_2',var_test=True, row_test=True, count_corrections=True, char_corrections='^')\n",
    "    file = open('./Stage3', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 4:\n",
    "    data.orgenizing_statistical_tests(start_row=1, stop_row=27, start_writer_h0=12, end_writer_h0=27,\n",
    "                                        type_of_test='permutation', test_name ='permutation_1_2',var_test=True, row_test=True, count_corrections=True, char_corrections='^')\n",
    "    file = open('./Stage4', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 5:\n",
    "    data.orgenizing_statistical_tests(start_row=1, stop_row=27, start_writer_h0=28, end_writer_h0=54,\n",
    "                                        type_of_test='permutation', test_name ='permutation_12_3',var_test=True, row_test=True, count_corrections=True, char_corrections='^')\n",
    "    file = open('./Stage5', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 6:\n",
    "    data.create_table_permutation_tests()\n",
    "    data.permutation_tests(start_row=12, stop_row=54, start_writer_h0=12, end_writer_h0=27, type_of_test='t_test',\n",
    "                            test_name='3:2_t_test', column_index_to_start=0, num_iterations=1000, var_test=True, row_test=True, count_corrections=True)\n",
    "    file = open('./Stage6', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 7:\n",
    "    data.permutation_tests(start_row=1, stop_row=27, start_writer_h0=12, end_writer_h0=27, type_of_test='t_test',\n",
    "                            test_name='1:2_t_test', column_index_to_start=0, num_iterations=1000, var_test=True, row_test=True, count_corrections=True)\n",
    "    file = open('./Stage7', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 8:\n",
    "    data.permutation_tests(start_row=12, stop_row=54, start_writer_h0=12, end_writer_h0=27, type_of_test='permutation',\n",
    "                            test_name='3:2_permutation', column_index_to_start=0, num_iterations=1000, var_test=True, row_test=True, count_corrections=True)\n",
    "    file = open('./Stage8', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "if STAGE < 9:\n",
    "    data.permutation_tests(start_row=1, stop_row=27, start_writer_h0=12, end_writer_h0=27, type_of_test='permutation',\n",
    "                            test_name='1:2__permutation', column_index_to_start=0, num_iterations=1000, var_test=True, row_test=True, count_corrections=True)\n",
    "    file = open('./Stage9', 'wb')\n",
    "    pickle.dump(data, file)\n",
    "    file.close()\n",
    "\n",
    "data.permutation_tests(start_row=1, stop_row=27, start_writer_h0=12, end_writer_h0=27, type_of_test='permutation',\n",
    "                        test_name='1:2__permutation', column_index_to_start=0, num_iterations=1000, var_test=True, row_test=True, count_corrections=True)\n",
    "file = open('./Stage10', 'wb')\n",
    "pickle.dump(data, file)\n",
    "file.close()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "first_row = data.data.iloc[(1,0)]  # Get the first row as a Series\n",
    "print(first_row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae410a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
